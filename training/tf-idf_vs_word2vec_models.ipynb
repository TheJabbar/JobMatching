{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Text Classification dengan TF-IDF dan Word2Vec**\n",
    "\n",
    "Dalam eksperimen ini, dua pendekatan representasi teks digunakan, yaitu **TF-IDF** dan **Word2Vec**, untuk memprediksi label `mentee_status` dari data teks gabungan (`combined_text`). Beragam model klasifikasi dievaluasi menggunakan **stratified 10-fold cross-validation** untuk menjaga keseimbangan distribusi label di setiap fold.\n",
    "\n",
    "üîç **Model yang diuji:**\n",
    "- Logistic Regression  \n",
    "- Ridge Classifier  \n",
    "- k-Nearest Neighbors  \n",
    "- Random Forest  \n",
    "- Linear SVC  \n",
    "- SGDClassifier (Log-loss)  \n",
    "- Nearest Centroid  \n",
    "- Complement Naive Bayes  \n",
    "\n",
    "üìè **Metode evaluasi:**\n",
    "- Precision  \n",
    "- Recall  \n",
    "- F1-Score (Macro Average)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Part 1: Text Classification using TF-IDF ‚úçÔ∏èüìä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode(\"utf-8\")) for s in docs) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset dan TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wbl_dataset(filepath, verbose=False):\n",
    "    \"\"\"\n",
    "    Load and vectorize the WBL mentee-mentor matching dataset.\n",
    "    \n",
    "    Param:\n",
    "        filepath (str): Path ke CSV file data kamu.\n",
    "        verbose (bool): Untuk menampilkan informasi proses.\n",
    "\n",
    "    Return:\n",
    "        X (TF-IDF matrix), y (labels), feature_names (list of terms), target_names (target labels), df (dataframe asli)\n",
    "    \"\"\"\n",
    "    # 1. Load data kamu dari CSV\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # 2. Gabungkan semua kolom teks relevan jadi satu kolom 'combined_text'\n",
    "    text_cols = [\n",
    "        'spv_mentee', 'job_position', 'required_tools', 'required_skills', \n",
    "        'required_role_title', 'mentee_name', 'mentee_title', 'mentee_skill',\n",
    "        'mentee_tools', 'mentee_position'\n",
    "    ]\n",
    "    df.fillna('', inplace=True)  # Hindari NaN\n",
    "    df['combined_text'] = df[text_cols].agg(' '.join, axis=1)\n",
    "\n",
    "    # 3. Target labels (misalnya 'mentee_status' untuk label target)\n",
    "    y = df['mentee_status']\n",
    "    target_names = y.unique()  # Mendapatkan nama kategori target (misalnya status mentee)\n",
    "    \n",
    "    # 4. TF-IDF vectorization\n",
    "    t0 = time()\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words='english')\n",
    "    X = vectorizer.fit_transform(df['combined_text'])\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    duration = time() - t0\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Dokumen: {len(df)}, Fitur: {X.shape[1]}\")\n",
    "        print(f\"TF-IDF selesai dalam {duration:.2f} detik\")\n",
    "\n",
    "    return X, y, feature_names, target_names, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, feature_names, target_names, df_raw = load_wbl_dataset(\"*/transformed_src/df_lowercased.csv\", verbose=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking Model Klasifikasi dengan Representasi TF-IDF dan 10-Fold Cross-Validation\n",
    "\n",
    "Berikut adalah hasil benchmark tiap model:\n",
    "\n",
    "| üß† Model               | üéØ Precision | üîÅ Recall | üèÜ F1-Score |\n",
    "| ---------------------- | ------------ | --------- | ----------- |\n",
    "| **Ridge Classifier**   | 0.983        | 0.980     | **0.981**   |\n",
    "| **Random Forest**      | 0.982        | 0.982     | **0.981**   |\n",
    "| Log-loss SGD           | 0.976        | 0.972     | 0.973       |\n",
    "| Logistic Regression    | 0.973        | 0.970     | 0.970       |\n",
    "| Linear SVC             | 0.973        | 0.970     | 0.970       |\n",
    "| Complement Naive Bayes | 0.960        | 0.956     | 0.957       |\n",
    "| Nearest Centroid       | 0.935        | 0.934     | 0.933       |\n",
    "| k-Nearest Neighbors    | 0.929        | 0.909     | 0.911       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "# Data\n",
    "X = df_raw['combined_text']\n",
    "y = df_raw['mentee_status']\n",
    "\n",
    "# TF-IDF vektorisasi\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words=\"english\")\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Daftar model yang akan diuji\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Ridge Classifier\": RidgeClassifier(tol=1e-2, solver=\"sparse_cg\"),\n",
    "    \"k-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Linear SVC\": LinearSVC(max_iter=1000),\n",
    "    \"Log-loss SGD\": SGDClassifier(loss=\"log_loss\", max_iter=1000, tol=1e-3, random_state=42),\n",
    "    \"Nearest Centroid\": NearestCentroid(),\n",
    "    \"Complement Naive Bayes\": ComplementNB()\n",
    "}\n",
    "\n",
    "# Dictionary untuk menyimpan hasil seluruh model\n",
    "all_results = {}\n",
    "\n",
    "# 10-fold stratified CV\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop ke semua model\n",
    "for model_name, clf in models.items():\n",
    "    print(f\"\\nEvaluating: {model_name}\")\n",
    "    results = {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": []\n",
    "    }\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X_tfidf, y), 1):\n",
    "        X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        results[\"precision\"].append(precision_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "        results[\"recall\"].append(recall_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "        results[\"f1_score\"].append(f1_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "\n",
    "        print(f\"  Fold {fold}: f1={results['f1_score'][-1]:.3f}\")\n",
    "\n",
    "    # Simpan hasil rata-rata\n",
    "    all_results[model_name] = {\n",
    "        \"Mean Precision\": np.mean(results[\"precision\"]),\n",
    "        \"Mean Recall\": np.mean(results[\"recall\"]),\n",
    "        \"Mean F1-Score\": np.mean(results[\"f1_score\"])\n",
    "    }\n",
    "\n",
    "# Tampilkan hasil akhir\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"Benchmarking Hasil Rata-Rata (10-Fold Cross-Validation):\\n\")\n",
    "\n",
    "results_df = pd.DataFrame(all_results).T  # Transpose agar lebih rapi\n",
    "print(results_df.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisasi Perbandingan Kinerja Model (10-Fold CV)\n",
    "\n",
    "##### üîù Performa Terbaik\n",
    "- **Random Forest**, **Ridge Classifier**, **Log-loss SGD**, dan **Logistic Regression** punya skor Precision, Recall, dan F1 tertinggi (~0.98‚Äì0.99).\n",
    "- Cocok untuk klasifikasi teks dengan performa stabil.\n",
    "\n",
    "##### ‚öñÔ∏è Performa Menengah\n",
    "- **Linear SVC** dan **Complement Naive Bayes** masih cukup bagus, meski sedikit di bawah empat model teratas.\n",
    "\n",
    "##### üîª Performa Terendah\n",
    "- **K-Nearest Neighbors (KNN)** dan **Nearest Centroid** menunjukkan performa paling rendah.\n",
    "- Kurang cocok untuk kasus teks ini.\n",
    "\n",
    "##### ‚úÖ Rekomendasi\n",
    "Gunakan **Ridge Classifier** atau **Logistic Regression** untuk hasil optimal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Urutkan data berdasarkan F1-Score tertinggi\n",
    "results_df_sorted = results_df.sort_values(by=\"Mean F1-Score\", ascending=False)\n",
    "\n",
    "# Ambil list model dan metrik\n",
    "models = results_df_sorted.index.tolist()\n",
    "metrics = [\"Mean Precision\", \"Mean Recall\", \"Mean F1-Score\"]\n",
    "\n",
    "# Data untuk setiap metrik\n",
    "data = [results_df_sorted[metric].values for metric in metrics]\n",
    "\n",
    "# Setup posisi bar\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(models))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot bar untuk tiap metrik per model\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(index + i * bar_width, data[i], bar_width, label=metric)\n",
    "\n",
    "# Label dan judul\n",
    "ax.set_xlabel(\"Models\")\n",
    "ax.set_ylabel(\"Skor\")\n",
    "ax.set_title(\"Perbandingan Kinerja Model (10-Fold CV)\")\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(models, rotation=45, ha=\"right\")\n",
    "ax.set_ylim(0, 1.05)  # agar ada ruang untuk label nilai\n",
    "\n",
    "# Grid untuk memudahkan pembacaan\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.6, axis='y')\n",
    "\n",
    "# Tambahkan nilai di atas setiap bar\n",
    "for i in range(len(models)):\n",
    "    for j in range(len(metrics)):\n",
    "        ax.text(index[i] + j*bar_width, data[j][i] + 0.02, f\"{data[j][i]:.3f}\",\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìó Part 2: Text Classification using Word2Vec üß†üó£Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation & Text Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load file yang sudah disimpan\n",
    "file_path = \"*/transformed_src/df_lowercased.csv\"\n",
    "df_lowercased = pd.read_csv(file_path)\n",
    "\n",
    "# Gabungkan kolom-kolom menjadi satu kolom 'text'\n",
    "df_lowercased['text'] = df_lowercased[['spv_mentee', 'job_position', 'required_tools', \n",
    "                                       'required_skills', 'required_role_title', 'mentee_name', \n",
    "                                       'mentee_title', 'mentee_skill', 'mentee_tools', \n",
    "                                       'mentee_position', 'mentee_status']\n",
    "                                      ].astype(str).agg(' '.join, axis=1)\n",
    "\n",
    "# Buat dataframe akhir untuk modeling\n",
    "df_combined = df_lowercased[['text', 'mentee_status']].rename(columns={'mentee_status': 'labels'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding & Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df_combined['labels'] = encoder.fit_transform(df_combined['labels'])\n",
    "\n",
    "X = df_combined['text']\n",
    "y = df_combined['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup NLTK Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Hapus semua path sebelumnya\n",
    "nltk.data.path.clear()\n",
    "\n",
    "# Tambahkan path yang benar\n",
    "nltk.data.path.append('*/nltk_data')\n",
    "\n",
    "# Verifikasi path yang digunakan\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.data.path.append('*/nltk_data')\n",
    "\n",
    "nltk.download('punkt', download_dir='*/nltk_data')\n",
    "nltk.download('stopwords', download_dir='*/nltk_data')\n",
    "nltk.download('punkt_tab', download_dir='*/nltk_data')\n",
    "\n",
    "# Fungsi preprocessing tanpa stemming\n",
    "def preprocess(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Menghapus karakter non-alfabet\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    \n",
    "    # Menurunkan semua huruf ke kecil\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tentukan bahasa berdasarkan kehadiran kata-kata bahasa Indonesia atau Inggris\n",
    "    stop_words_en = set(stopwords.words('english'))\n",
    "    stop_words_id = set(stopwords.words('indonesian'))\n",
    "    \n",
    "    # Tentukan stopwords dan bahasa\n",
    "    words = nltk.word_tokenize(text)\n",
    "    language = 'id' if any(word in stop_words_id for word in words) else 'en'\n",
    "\n",
    "    if language == 'en':\n",
    "        stop_words = stop_words_en\n",
    "    else:\n",
    "        stop_words = stop_words_id\n",
    "    \n",
    "    # Tokenisasi dan hapus stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Preprocessing to Train & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.Series(X_train)\n",
    "X_test = pd.Series(X_test)\n",
    "\n",
    "# Tidak usah isi NaN, biarkan tetap kosong\n",
    "X_train = X_train.apply(preprocess)\n",
    "X_test = X_test.apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "VECTOR_SIZE = 100\n",
    "WINDOW = 50\n",
    "MIN_COUNT = 5\n",
    "\n",
    "sentences = [sentence.split() for sentence in X_train]\n",
    "w2v_model = Word2Vec(sentences, vector_size=VECTOR_SIZE, window=WINDOW, min_count=MIN_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize(sentence):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(VECTOR_SIZE)\n",
    "    return np.mean(words_vecs, axis=0)\n",
    "\n",
    "X_train_vec = np.array([vectorize(sentence) for sentence in X_train])\n",
    "X_test_vec = np.array([vectorize(sentence) for sentence in X_test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking Model Klasifikasi dengan Representasi Word2Vec dan 10-Fold Cross-Validation\n",
    "\n",
    "| Model               | Mean Precision | Mean Recall | Mean F1-Score | Avg Train Time (s) | Avg Test Time (s) |\n",
    "|---------------------|----------------|-------------|---------------|--------------------|-------------------|\n",
    "| Logistic Regression  | 0.799          | 0.790       | 0.790         | 0.005              | 0.000             |\n",
    "| Ridge Classifier     | 0.796          | 0.784       | 0.785         | 0.002              | 0.000             |\n",
    "| k-Nearest Neighbors  | 0.932          | 0.930       | 0.930         | 0.001              | 0.002             |\n",
    "| Random Forest       | **0.982**      | **0.981**   | **0.981**     | 0.226              | 0.008             |\n",
    "| Linear SVC           | 0.778          | 0.706       | 0.691         | 0.002              | 0.000             |\n",
    "| Log-loss SGD         | 0.498          | 0.541       | 0.418         | 0.004              | 0.000             |\n",
    "| Nearest Centroid     | 0.756          | 0.751       | 0.751         | 0.001              | 0.001             |\n",
    "\n",
    "\n",
    "\n",
    "> **Kesimpulan singkat:**\n",
    "> - Random Forest tampil sebagai model terbaik dengan performa F1-Score tertinggi (0.981) meski waktu trainingnya paling lama.\n",
    "> - k-Nearest Neighbors juga sangat baik dengan F1-Score 0.930 dan waktu training/testing yang sangat cepat.\n",
    "> - Log-loss SGD memiliki performa paling rendah di antara model yang diuji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "# Daftar model\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(C=5, max_iter=1000),\n",
    "    \"Ridge Classifier\": RidgeClassifier(alpha=1.0, solver=\"sparse_cg\"),\n",
    "    \"k-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Linear SVC\": LinearSVC(C=0.1, dual=False, max_iter=1000),\n",
    "    \"Log-loss SGD\": SGDClassifier(loss=\"log_loss\", alpha=1e-4, n_iter_no_change=3, early_stopping=True),\n",
    "    \"Nearest Centroid\": NearestCentroid()\n",
    "}\n",
    "\n",
    "# Cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "all_results = {}\n",
    "\n",
    "X_clean = X.apply(preprocess)\n",
    "X_w2v = np.array([vectorize(sentence) for sentence in X_clean])\n",
    "\n",
    "\n",
    "# Uji semua model\n",
    "for model_name, clf in models.items():\n",
    "    print(f\"\\nEvaluating: {model_name}\")\n",
    "    results = {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": [],\n",
    "        \"train_time\": [],\n",
    "        \"test_time\": []\n",
    "    }\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X_w2v, y), 1):\n",
    "        X_train, X_test = X_w2v[train_idx], X_w2v[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        t0 = time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_duration = time() - t0\n",
    "\n",
    "        t0 = time()\n",
    "        y_pred = clf.predict(X_test)\n",
    "        test_duration = time() - t0\n",
    "\n",
    "        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "        results[\"precision\"].append(prec)\n",
    "        results[\"recall\"].append(rec)\n",
    "        results[\"f1_score\"].append(f1)\n",
    "        results[\"train_time\"].append(train_duration)\n",
    "        results[\"test_time\"].append(test_duration)\n",
    "\n",
    "        print(f\"  f1={f1:.3f}\")\n",
    "\n",
    "    # Simpan rata-rata hasil\n",
    "    all_results[model_name] = {\n",
    "        \"Mean Precision\": np.mean(results[\"precision\"]),\n",
    "        \"Mean Recall\": np.mean(results[\"recall\"]),\n",
    "        \"Mean F1-Score\": np.mean(results[\"f1_score\"]),\n",
    "        \"Avg Train Time\": np.mean(results[\"train_time\"]),\n",
    "        \"Avg Test Time\": np.mean(results[\"test_time\"]),\n",
    "    }\n",
    "\n",
    "# Tampilkan hasil akhir dalam bentuk DataFrame\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"Benchmarking Hasil Rata-Rata (Word2Vec + 10-Fold Cross-Validation):\\n\")\n",
    "\n",
    "results_df = pd.DataFrame(all_results).T\n",
    "print(results_df.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisasi Perbandingan Kinerja Model (10-Fold CV)\n",
    "\n",
    "##### üîù Performa Terbaik\n",
    "\n",
    "* **Random Forest** dan **k-Nearest Neighbors** unggul dengan skor F1 di atas 0.90.\n",
    "* Cocok untuk tugas klasifikasi dengan hasil paling stabil dan akurat.\n",
    "\n",
    "##### ‚öñÔ∏è Performa Menengah\n",
    "\n",
    "* **Logistic Regression**, **Ridge Classifier**, dan **Nearest Centroid** memiliki performa cukup baik dengan skor F1 sekitar 0.75-0.79.\n",
    "\n",
    "##### üîª Performa Terendah\n",
    "\n",
    "* **Linear SVC** dan **Log-loss SGD** menunjukkan performa paling rendah, terutama Log-loss SGD dengan F1 sekitar 0.42.\n",
    "* Kurang direkomendasikan untuk data ini.\n",
    "\n",
    "##### ‚úÖ Rekomendasi\n",
    "\n",
    "Gunakan **Random Forest** untuk hasil terbaik, atau **k-Nearest Neighbors** sebagai alternatif kuat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ambil data hasil benchmark\n",
    "results_df = pd.DataFrame(all_results).T\n",
    "\n",
    "# Urutan model dan metrik\n",
    "models = results_df.index.tolist()\n",
    "metrics = ['Mean Precision', 'Mean Recall', 'Mean F1-Score']\n",
    "\n",
    "# Data untuk setiap metrik\n",
    "data = [results_df[metric].values for metric in metrics]\n",
    "\n",
    "# Setup posisi bar\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(models))\n",
    "\n",
    "# Membuat figure dan axis\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Plot tiap metrik sebagai bar yang berdampingan\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(index + i * bar_width, data[i], bar_width, label=metric)\n",
    "\n",
    "# Label dan judul\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Perbandingan Kinerja Model (10-Fold CV)')\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax.set_ylim(0, 1.05)  # supaya ada ruang di atas\n",
    "\n",
    "# Tambahkan legend\n",
    "ax.legend()\n",
    "\n",
    "# Tampilkan nilai di atas setiap bar\n",
    "for i in range(len(models)):\n",
    "    for j in range(len(metrics)):\n",
    "        ax.text(index[i] + j*bar_width, data[j][i] + 0.02, f\"{data[j][i]:.3f}\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualisasi waktu training dan testing (opsional)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training time\n",
    "axes[0].barh(results_df.index, results_df['Avg Train Time'], color=colors)\n",
    "axes[0].set_title('Average Training Time (seconds)')\n",
    "axes[0].invert_yaxis()\n",
    "for idx, val in enumerate(results_df['Avg Train Time']):\n",
    "    axes[0].text(val + max(results_df['Avg Train Time'])*0.01, idx, f\"{val:.3f}\", va='center')\n",
    "\n",
    "# Testing time\n",
    "axes[1].barh(results_df.index, results_df['Avg Test Time'], color=colors)\n",
    "axes[1].set_title('Average Testing Time (seconds)')\n",
    "axes[1].invert_yaxis()\n",
    "for idx, val in enumerate(results_df['Avg Test Time']):\n",
    "    axes[1].text(val + max(results_df['Avg Test Time'])*0.01, idx, f\"{val:.3f}\", va='center')\n",
    "\n",
    "plt.suptitle('Comparison of Model Computational Time', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobmatch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
