{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ðŸ“Œ **Loading and vectorizing the text dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode(\"utf-8\")) for s in docs) / 1e6\n",
    "\n",
    "def load_wbl_dataset(filepath, verbose=False):\n",
    "    \"\"\"\n",
    "    Load and vectorize the WBL mentee-mentor matching dataset.\n",
    "    \n",
    "    Param:\n",
    "        filepath (str): Path ke CSV file data kamu.\n",
    "        verbose (bool): Untuk menampilkan informasi proses.\n",
    "\n",
    "    Return:\n",
    "        X (TF-IDF matrix), y (labels), feature_names (list of terms), target_names (target labels), df (dataframe asli)\n",
    "    \"\"\"\n",
    "    # 1. Load data kamu dari CSV\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # 2. Gabungkan semua kolom teks relevan jadi satu kolom 'combined_text'\n",
    "    text_cols = [\n",
    "        'spv_mentee', 'job_position', 'required_tools', 'required_skills', \n",
    "        'required_role_title', 'mentee_name', 'mentee_title', 'mentee_skill',\n",
    "        'mentee_tools', 'mentee_position'\n",
    "    ]\n",
    "    df.fillna('', inplace=True)  # Hindari NaN\n",
    "    df['combined_text'] = df[text_cols].agg(' '.join, axis=1)\n",
    "\n",
    "    # 3. Target labels (misalnya 'mentee_status' untuk label target)\n",
    "    y = df['mentee_status']\n",
    "    target_names = y.unique()  # Mendapatkan nama kategori target (misalnya status mentee)\n",
    "    \n",
    "    # 4. TF-IDF vectorization\n",
    "    t0 = time()\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words='english')\n",
    "    X = vectorizer.fit_transform(df['combined_text'])\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    duration = time() - t0\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Dokumen: {len(df)}, Fitur: {X.shape[1]}\")\n",
    "        print(f\"TF-IDF selesai dalam {duration:.2f} detik\")\n",
    "\n",
    "    return X, y, feature_names, target_names, df\n",
    "\n",
    "# 2. Load dan split data\n",
    "X, y, feature_names, target_names, df_raw = load_wbl_dataset(\"/Users/sonya/Downloads/JobMatching/transformed_src/df_lowercased.csv\", verbose=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 3. Train classifier\n",
    "clf = RidgeClassifier(tol=1e-2, solver=\"sparse_cg\")\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# 4. Confusion Matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred, ax=ax)\n",
    "ax.xaxis.set_ticklabels(target_names, rotation=45)\n",
    "ax.yaxis.set_ticklabels(target_names)\n",
    "_ = ax.set_title(f\"Confusion Matrix for {clf.__class__.__name__}\\non WBL Job Matching\")\n",
    "\n",
    "# 5. Plot top keywords per class\n",
    "def plot_feature_effects():\n",
    "    avg_feature_effects = clf.coef_ * np.asarray(X_train.mean(axis=0)).ravel()\n",
    "    top = pd.DataFrame()\n",
    "    top_indices = []\n",
    "\n",
    "    # Jika hanya satu kelas (binary)\n",
    "    if len(clf.classes_) == 2 and len(avg_feature_effects.shape) == 1:\n",
    "        top5 = np.argsort(avg_feature_effects)[-5:][::-1]\n",
    "        top[clf.classes_[1]] = feature_names[top5]  # Gunakan positive class\n",
    "        top_indices.extend(top5)\n",
    "        avg_feature_effects = avg_feature_effects.reshape(1, -1)\n",
    "    else:\n",
    "        for i, label in enumerate(clf.classes_):\n",
    "            top5 = np.argsort(avg_feature_effects[i])[-5:][::-1]\n",
    "            top[label] = feature_names[top5]\n",
    "            top_indices.extend(top5)\n",
    "\n",
    "    top_indices = np.unique(top_indices)\n",
    "    predictive_words = feature_names[top_indices]\n",
    "\n",
    "    # Visualisasi bar horizontal\n",
    "    bar_size = 0.25\n",
    "    padding = 0.75\n",
    "    y_locs = np.arange(len(top_indices)) * (4 * bar_size + padding)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    for i, label in enumerate(clf.classes_):\n",
    "        ax.barh(\n",
    "            y_locs + (i - 2) * bar_size,\n",
    "            avg_feature_effects[i, top_indices] if avg_feature_effects.ndim > 1 else avg_feature_effects[top_indices],\n",
    "            height=bar_size,\n",
    "            label=label,\n",
    "        )\n",
    "    ax.set(\n",
    "        yticks=y_locs,\n",
    "        yticklabels=predictive_words,\n",
    "        ylim=[0 - 4 * bar_size, len(top_indices) * (4 * bar_size + padding) - 4 * bar_size],\n",
    "    )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    print(\"Top 5 keywords per class:\")\n",
    "    print(top)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_raw.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label di training:\", pd.Series(y_train).value_counts())\n",
    "print(\"Label di testing:\", pd.Series(y_test).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of a bag-of-words document classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without metadata stripping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Train classifier\n",
    "clf = RidgeClassifier(tol=1e-2, solver=\"sparse_cg\")\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# 4. Confusion Matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred, ax=ax)\n",
    "ax.xaxis.set_ticklabels(target_names, rotation=45)\n",
    "ax.yaxis.set_ticklabels(target_names)\n",
    "_ = ax.set_title(f\"Confusion Matrix for {clf.__class__.__name__}\\non WBL Job Matching\")\n",
    "\n",
    "# 5. Plot top keywords per class\n",
    "def plot_feature_effects():\n",
    "    average_feature_effects = clf.coef_ * np.asarray(X_train.mean(axis=0)).ravel()\n",
    "\n",
    "    top_indices = []\n",
    "    top = pd.DataFrame()\n",
    "\n",
    "    # Cek apakah average_feature_effects berdimensi 2 (multiclass) atau 1 (binary)\n",
    "    if average_feature_effects.ndim == 2:\n",
    "        # Multiclass case\n",
    "        for i, label in enumerate(clf.classes_):\n",
    "            top5 = np.argsort(average_feature_effects[i])[-5:][::-1]\n",
    "            top[label] = [feature_names[i] for i in top5]\n",
    "            top_indices.extend(top5)\n",
    "        top_indices = np.unique(top_indices)\n",
    "        predictive_words = [feature_names[i] for i in top_indices]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        bar_size = 0.25\n",
    "        padding = 0.75\n",
    "        y_locs = np.arange(len(top_indices)) * (4 * bar_size + padding)\n",
    "\n",
    "        for i, label in enumerate(clf.classes_):\n",
    "            ax.barh(\n",
    "                y_locs + (i - 2) * bar_size,\n",
    "                average_feature_effects[i][top_indices],\n",
    "                height=bar_size,\n",
    "                label=str(label),\n",
    "            )\n",
    "    else:\n",
    "        # Binary case\n",
    "        top5 = np.argsort(average_feature_effects)[-5:][::-1]\n",
    "        top[\"Top Features\"] = [feature_names[i] for i in top5]\n",
    "        top_indices = top5\n",
    "        predictive_words = [feature_names[i] for i in top_indices]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        bar_size = 0.35\n",
    "        y_locs = np.arange(len(top_indices))\n",
    "\n",
    "        ax.barh(\n",
    "            y_locs,\n",
    "            average_feature_effects[top_indices],\n",
    "            height=bar_size,\n",
    "            label=\"Average Feature Effect\",\n",
    "        )\n",
    "\n",
    "    ax.set(\n",
    "        yticks=y_locs,\n",
    "        yticklabels=predictive_words,\n",
    "        ylim=[-1, len(top_indices)],\n",
    "    )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    print(\"Top 5 keywords per class:\")\n",
    "    print(top)\n",
    "\n",
    "    return ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with metadata stripping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Train model\n",
    "clf = RidgeClassifier(tol=1e-2, solver=\"sparse_cg\")\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# 3. Confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred, ax=ax)\n",
    "ax.xaxis.set_ticklabels(target_names, rotation=45)\n",
    "ax.yaxis.set_ticklabels(target_names)\n",
    "_ = ax.set_title(f\"Confusion Matrix for {clf.__class__.__name__}\\non filtered metadata WBL documents\")\n",
    "\n",
    "# 4. Feature effects\n",
    "def plot_feature_effects():\n",
    "    average_feature_effects = clf.coef_ * np.asarray(X_train.mean(axis=0)).ravel()\n",
    "\n",
    "    top_indices = []\n",
    "    top = pd.DataFrame()\n",
    "\n",
    "    # Cek apakah average_feature_effects adalah 2D atau 1D\n",
    "    if len(average_feature_effects.shape) == 2:\n",
    "        # Multiclass atau binary dengan coef_ shape = (2, n_features)\n",
    "        for i, label in enumerate(clf.classes_):\n",
    "            top5 = np.argsort(average_feature_effects[i])[-5:][::-1]\n",
    "            top[label] = [feature_names[j] for j in top5]\n",
    "            top_indices.extend(top5)\n",
    "\n",
    "        top_indices = np.unique(top_indices)\n",
    "        predictive_words = [feature_names[j] for j in top_indices]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        bar_size = 0.25\n",
    "        padding = 0.75\n",
    "        y_locs = np.arange(len(top_indices)) * (4 * bar_size + padding)\n",
    "\n",
    "        for i, label in enumerate(clf.classes_):\n",
    "            ax.barh(\n",
    "                y_locs + (i - 2) * bar_size,\n",
    "                average_feature_effects[i][top_indices],\n",
    "                height=bar_size,\n",
    "                label=label,\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        # Binary classifier with coef_ shape = (n_features,)\n",
    "        top5 = np.argsort(average_feature_effects)[-5:][::-1]\n",
    "        top[\"Top Features\"] = [feature_names[j] for j in top5]\n",
    "        top_indices = top5\n",
    "        predictive_words = [feature_names[j] for j in top_indices]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        bar_size = 0.35\n",
    "        y_locs = np.arange(len(top_indices))\n",
    "\n",
    "        ax.barh(\n",
    "            y_locs,\n",
    "            average_feature_effects[top_indices],\n",
    "            height=bar_size,\n",
    "            label=\"Feature Importance\",\n",
    "        )\n",
    "\n",
    "    ax.set(\n",
    "        yticks=y_locs,\n",
    "        yticklabels=predictive_words,\n",
    "        ylim=[-1, len(top_indices)],\n",
    "    )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    print(\"Top 5 keywords per class:\")\n",
    "    print(top)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.utils.extmath import density\n",
    "from time import time\n",
    "\n",
    "def benchmark(clf, custom_name=False):\n",
    "    print(\"_\" * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(f\"train time: {train_time:.3f}s\")\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(f\"test time:  {test_time:.3f}s\")\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(f\"accuracy:   {score:.3f}\")\n",
    "\n",
    "    if hasattr(clf, \"coef_\"):\n",
    "        print(f\"dimensionality: {clf.coef_.shape[1]}\")\n",
    "        print(f\"density: {density(clf.coef_)}\")\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(custom_name) if custom_name else clf.__class__.__name__\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "\n",
    "# Fungsi optional: menghitung densitas bobot\n",
    "def density(coef):\n",
    "    return np.mean(coef != 0)\n",
    "\n",
    "# Fungsi benchmarking\n",
    "def benchmark(clf, custom_name):\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    precision = precision_score(y_test, pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, pred, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"Model: {custom_name}\")\n",
    "    print(f\"Precision:  {precision:.3f}\")\n",
    "    print(f\"Recall:     {recall:.3f}\")\n",
    "    print(f\"F1-Score:   {f1:.3f}\")\n",
    "\n",
    "    if hasattr(clf, \"coef_\"):\n",
    "        shape = clf.coef_.shape\n",
    "        if len(shape) == 2:\n",
    "            print(f\"Dimensionality: {shape[1]}\")\n",
    "        elif len(shape) == 1:\n",
    "            print(f\"Dimensionality: {shape[0]}\")\n",
    "        print(f\"Density: {density(clf.coef_)}\")\n",
    "\n",
    "    print()\n",
    "    return (custom_name, accuracy, precision, recall, f1)\n",
    "\n",
    "# Daftar model\n",
    "models = [\n",
    "    (LogisticRegression(C=5, max_iter=1000), \"Logistic Regression\"),\n",
    "    (RidgeClassifier(alpha=1.0, solver=\"sparse_cg\"), \"Ridge Classifier\"),\n",
    "    (KNeighborsClassifier(n_neighbors=5), \"k-Nearest Neighbors\"),\n",
    "    (RandomForestClassifier(n_estimators=100, random_state=42), \"Random Forest\"),\n",
    "    (LinearSVC(C=0.1, dual=False, max_iter=1000), \"Linear SVC\"),\n",
    "    (\n",
    "        SGDClassifier(loss=\"log_loss\", alpha=1e-4, n_iter_no_change=3, early_stopping=True),\n",
    "        \"Log-loss SGD\",\n",
    "    ),\n",
    "    (NearestCentroid(), \"Nearest Centroid\"),\n",
    "    (ComplementNB(alpha=0.1), \"Complement Naive Bayes\"),\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Benchmarking berbagai model klasifikasi untuk prediksi mentee_status\\n\")\n",
    "\n",
    "for clf, name in models:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Evaluasi: {name}\")\n",
    "    results.append(benchmark(clf, name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Model - Model Klasifikasi\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_raw['combined_text']  \n",
    "y = df_raw['mentee_status']  \n",
    "\n",
    "# Inisialisasi StratifiedKFold dengan 5 fold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Menyimpan hasil evaluasi per fold\n",
    "results = {\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1_score\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    \n",
    "    # Menampilkan indeks train dan test untuk fold ini\n",
    "    print(f\"  Train indices: {train_index}\")\n",
    "    print(f\"  Test indices: {test_index}\")\n",
    "    \n",
    "    # Membagi data training dan testing berdasarkan fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Vectorisasi teks menggunakan TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words=\"english\")\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    # Model klasifikasi \n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    \n",
    "    # Prediksi dan evaluasi\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Menyimpan hasil evaluasi untuk fold ini\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"recall\"].append(recall)\n",
    "    results[\"f1_score\"].append(f1)\n",
    "    \n",
    "    # Menampilkan hasil untuk fold ini\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\")\n",
    "\n",
    "# Menampilkan hasil rata-rata dari seluruh fold\n",
    "print(\"=\"*80)\n",
    "print(\"Rata-rata hasil evaluasi dari seluruh fold:\")\n",
    "print(f\"Mean Precision:  {np.mean(results['precision']):.3f}\")\n",
    "print(f\"Mean Recall:     {np.mean(results['recall']):.3f}\")\n",
    "print(f\"Mean F1-Score:   {np.mean(results['f1_score']):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    \n",
    "    # Menampilkan indeks train dan test untuk fold ini\n",
    "    print(f\"  Train indices: {train_index}\")\n",
    "    print(f\"  Test indices: {test_index}\")\n",
    "    \n",
    "    # Membagi data training dan testing berdasarkan fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Vectorisasi teks menggunakan TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words=\"english\")\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    # Model klasifikasi \n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    \n",
    "    # Prediksi dan evaluasi\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Menyimpan hasil evaluasi untuk fold ini\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"recall\"].append(recall)\n",
    "    results[\"f1_score\"].append(f1)\n",
    "    \n",
    "    # Menampilkan hasil untuk fold ini\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\")\n",
    "\n",
    "# Menampilkan hasil rata-rata dari seluruh fold\n",
    "print(\"=\"*80)\n",
    "print(\"Rata-rata hasil evaluasi dari seluruh fold:\")\n",
    "print(f\"Mean Precision:  {np.mean(results['precision']):.3f}\")\n",
    "print(f\"Mean Recall:     {np.mean(results['recall']):.3f}\")\n",
    "print(f\"Mean F1-Score:   {np.mean(results['f1_score']):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    \n",
    "    # Menampilkan indeks train dan test untuk fold ini\n",
    "    print(f\"  Train indices: {train_index}\")\n",
    "    print(f\"  Test indices: {test_index}\")\n",
    "    \n",
    "    # Membagi data training dan testing berdasarkan fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Vectorisasi teks menggunakan TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words=\"english\")\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    # Model klasifikasi \n",
    "    clf = KNeighborsClassifier(n_neighbors=5)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    \n",
    "    # Prediksi dan evaluasi\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Menyimpan hasil evaluasi untuk fold ini\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"recall\"].append(recall)\n",
    "    results[\"f1_score\"].append(f1)\n",
    "    \n",
    "    # Menampilkan hasil untuk fold ini\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\")\n",
    "\n",
    "# Menampilkan hasil rata-rata dari seluruh fold\n",
    "print(\"=\"*80)\n",
    "print(\"Rata-rata hasil evaluasi dari seluruh fold:\")\n",
    "print(f\"Mean Precision:  {np.mean(results['precision']):.3f}\")\n",
    "print(f\"Mean Recall:     {np.mean(results['recall']):.3f}\")\n",
    "print(f\"Mean F1-Score:   {np.mean(results['f1_score']):.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    \n",
    "    # Menampilkan indeks train dan test untuk fold ini\n",
    "    print(f\"  Train indices: {train_index}\")\n",
    "    print(f\"  Test indices: {test_index}\")\n",
    "    \n",
    "    # Membagi data training dan testing berdasarkan fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Vectorisasi teks menggunakan TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words=\"english\")\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    # Model klasifikasi \n",
    "    clf = KNeighborsClassifier(n_neighbors=5)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    \n",
    "    # Prediksi dan evaluasi\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Menyimpan hasil evaluasi untuk fold ini\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"recall\"].append(recall)\n",
    "    results[\"f1_score\"].append(f1)\n",
    "    \n",
    "    # Menampilkan hasil untuk fold ini\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\")\n",
    "\n",
    "# Menampilkan hasil rata-rata dari seluruh fold\n",
    "print(\"=\"*80)\n",
    "print(\"Rata-rata hasil evaluasi dari seluruh fold:\")\n",
    "print(f\"Mean Precision:  {np.mean(results['precision']):.3f}\")\n",
    "print(f\"Mean Recall:     {np.mean(results['recall']):.3f}\")\n",
    "print(f\"Mean F1-Score:   {np.mean(results['f1_score']):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    \n",
    "    # Menampilkan indeks train dan test untuk fold ini\n",
    "    print(f\"  Train indices: {train_index}\")\n",
    "    print(f\"  Test indices: {test_index}\")\n",
    "    \n",
    "    # Membagi data training dan testing berdasarkan fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Vectorisasi teks menggunakan TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words=\"english\")\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    # Model klasifikasi \n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    \n",
    "    # Prediksi dan evaluasi\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Menyimpan hasil evaluasi untuk fold ini\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"recall\"].append(recall)\n",
    "    results[\"f1_score\"].append(f1)\n",
    "    \n",
    "    # Menampilkan hasil untuk fold ini\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\")\n",
    "\n",
    "# Menampilkan hasil rata-rata dari seluruh fold\n",
    "print(\"=\"*80)\n",
    "print(\"Rata-rata hasil evaluasi dari seluruh fold:\")\n",
    "print(f\"Mean Precision:  {np.mean(results['precision']):.3f}\")\n",
    "print(f\"Mean Recall:     {np.mean(results['recall']):.3f}\")\n",
    "print(f\"Mean F1-Score:   {np.mean(results['f1_score']):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    \n",
    "    # Menampilkan indeks train dan test untuk fold ini\n",
    "    print(f\"  Train indices: {train_index}\")\n",
    "    print(f\"  Test indices: {test_index}\")\n",
    "    \n",
    "    # Membagi data training dan testing berdasarkan fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Vectorisasi teks menggunakan TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words=\"english\")\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    # Model klasifikasi \n",
    "    clf = LinearSVC(max_iter=1000)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    \n",
    "    # Prediksi dan evaluasi\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Menyimpan hasil evaluasi untuk fold ini\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"recall\"].append(recall)\n",
    "    results[\"f1_score\"].append(f1)\n",
    "    \n",
    "    # Menampilkan hasil untuk fold ini\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\")\n",
    "\n",
    "# Menampilkan hasil rata-rata dari seluruh fold\n",
    "print(\"=\"*80)\n",
    "print(\"Rata-rata hasil evaluasi dari seluruh fold:\")\n",
    "print(f\"Mean Precision:  {np.mean(results['precision']):.3f}\")\n",
    "print(f\"Mean Recall:     {np.mean(results['recall']):.3f}\")\n",
    "print(f\"Mean F1-Score:   {np.mean(results['f1_score']):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    \n",
    "    # Menampilkan indeks train dan test untuk fold ini\n",
    "    print(f\"  Train indices: {train_index}\")\n",
    "    print(f\"  Test indices: {test_index}\")\n",
    "    \n",
    "    # Membagi data training dan testing berdasarkan fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Vectorisasi teks menggunakan TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words=\"english\")\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    # Model klasifikasi \n",
    "    clf = SGDClassifier(loss=\"log_loss\", max_iter=1000, tol=1e-3, random_state=42)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    \n",
    "    # Prediksi dan evaluasi\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Menyimpan hasil evaluasi untuk fold ini\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"recall\"].append(recall)\n",
    "    results[\"f1_score\"].append(f1)\n",
    "    \n",
    "    # Menampilkan hasil untuk fold ini\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\")\n",
    "\n",
    "# Menampilkan hasil rata-rata dari seluruh fold\n",
    "print(\"=\"*80)\n",
    "print(\"Rata-rata hasil evaluasi dari seluruh fold:\")\n",
    "print(f\"Mean Precision:  {np.mean(results['precision']):.3f}\")\n",
    "print(f\"Mean Recall:     {np.mean(results['recall']):.3f}\")\n",
    "print(f\"Mean F1-Score:   {np.mean(results['f1_score']):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    \n",
    "    # Menampilkan indeks train dan test untuk fold ini\n",
    "    print(f\"  Train indices: {train_index}\")\n",
    "    print(f\"  Test indices: {test_index}\")\n",
    "    \n",
    "    # Membagi data training dan testing berdasarkan fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Vectorisasi teks menggunakan TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words=\"english\")\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    # Model klasifikasi \n",
    "    clf = NearestCentroid()\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    \n",
    "    # Prediksi dan evaluasi\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Menyimpan hasil evaluasi untuk fold ini\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"recall\"].append(recall)\n",
    "    results[\"f1_score\"].append(f1)\n",
    "    \n",
    "    # Menampilkan hasil untuk fold ini\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\")\n",
    "\n",
    "# Menampilkan hasil rata-rata dari seluruh fold\n",
    "print(\"=\"*80)\n",
    "print(\"Rata-rata hasil evaluasi dari seluruh fold:\")\n",
    "print(f\"Mean Precision:  {np.mean(results['precision']):.3f}\")\n",
    "print(f\"Mean Recall:     {np.mean(results['recall']):.3f}\")\n",
    "print(f\"Mean F1-Score:   {np.mean(results['f1_score']):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    \n",
    "    # Menampilkan indeks train dan test untuk fold ini\n",
    "    print(f\"  Train indices: {train_index}\")\n",
    "    print(f\"  Test indices: {test_index}\")\n",
    "    \n",
    "    # Membagi data training dan testing berdasarkan fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Vectorisasi teks menggunakan TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words=\"english\")\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    # Model klasifikasi \n",
    "    clf = ComplementNB()\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    \n",
    "    # Prediksi dan evaluasi\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Menyimpan hasil evaluasi untuk fold ini\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"recall\"].append(recall)\n",
    "    results[\"f1_score\"].append(f1)\n",
    "    \n",
    "    # Menampilkan hasil untuk fold ini\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\")\n",
    "\n",
    "# Menampilkan hasil rata-rata dari seluruh fold\n",
    "print(\"=\"*80)\n",
    "print(\"Rata-rata hasil evaluasi dari seluruh fold:\")\n",
    "print(f\"Mean Precision:  {np.mean(results['precision']):.3f}\")\n",
    "print(f\"Mean Recall:     {np.mean(results['recall']):.3f}\")\n",
    "print(f\"Mean F1-Score:   {np.mean(results['f1_score']):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "# Data\n",
    "X = df_raw['combined_text']\n",
    "y = df_raw['mentee_status']\n",
    "\n",
    "# TF-IDF vektorisasi\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=2, stop_words=\"english\")\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Daftar model yang akan diuji\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Ridge Classifier\": RidgeClassifier(tol=1e-2, solver=\"sparse_cg\"),\n",
    "    \"k-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Linear SVC\": LinearSVC(max_iter=1000),\n",
    "    \"Log-loss SGD\": SGDClassifier(loss=\"log_loss\", max_iter=1000, tol=1e-3, random_state=42),\n",
    "    \"Nearest Centroid\": NearestCentroid(),\n",
    "    \"Complement Naive Bayes\": ComplementNB()\n",
    "}\n",
    "\n",
    "# Dictionary untuk menyimpan hasil seluruh model\n",
    "all_results = {}\n",
    "\n",
    "# 10-fold stratified CV\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop ke semua model\n",
    "for model_name, clf in models.items():\n",
    "    print(f\"\\nEvaluating: {model_name}\")\n",
    "    results = {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": []\n",
    "    }\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X_tfidf, y), 1):\n",
    "        X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        results[\"precision\"].append(precision_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "        results[\"recall\"].append(recall_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "        results[\"f1_score\"].append(f1_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "\n",
    "        print(f\"  Fold {fold}: f1={results['f1_score'][-1]:.3f}\")\n",
    "\n",
    "    # Simpan hasil rata-rata\n",
    "    all_results[model_name] = {\n",
    "        \"Mean Precision\": np.mean(results[\"precision\"]),\n",
    "        \"Mean Recall\": np.mean(results[\"recall\"]),\n",
    "        \"Mean F1-Score\": np.mean(results[\"f1_score\"])\n",
    "    }\n",
    "\n",
    "# Tampilkan hasil akhir\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"Benchmarking Hasil Rata-Rata (10-Fold Cross-Validation):\\n\")\n",
    "\n",
    "results_df = pd.DataFrame(all_results).T  # Transpose agar lebih rapi\n",
    "print(results_df.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Urutkan berdasarkan F1-Score tertinggi\n",
    "results_df_sorted = results_df.sort_values(by=\"Mean F1-Score\", ascending=False)\n",
    "\n",
    "# Plot bar chart\n",
    "results_df_sorted.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title(\"Perbandingan Kinerja Model (10-Fold CV)\")\n",
    "plt.ylabel(\"Skor\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot accuracy, training and test time of each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def benchmark(clf, custom_name):\n",
    "    start_train = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_train\n",
    "\n",
    "    start_test = time.time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time.time() - start_test\n",
    "\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    print(f\"Train time: {train_time:.3f}s | Test time: {test_time:.3f}s\")\n",
    "    \n",
    "    # Kembalikan tuple dengan 4 elemen\n",
    "    return (custom_name, score, train_time, test_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menambahkan hasil benchmarking ke dalam results sesuai dengan model yang telah didefinisikan\n",
    "results.append(benchmark(LogisticRegression(C=5, max_iter=1000), \"Logistic Regression\"))\n",
    "results.append(benchmark(RidgeClassifier(alpha=1.0, solver=\"sparse_cg\"), \"Ridge Classifier\"))\n",
    "results.append(benchmark(KNeighborsClassifier(n_neighbors=5), \"k-Nearest Neighbors\"))\n",
    "results.append(benchmark(RandomForestClassifier(n_estimators=100, random_state=42), \"Random Forest\"))\n",
    "results.append(benchmark(LinearSVC(C=0.1, dual=False, max_iter=1000), \"Linear SVC\"))\n",
    "results.append(benchmark(SGDClassifier(loss=\"log_loss\", alpha=1e-4, n_iter_no_change=3, early_stopping=True), \"Log-loss SGD\"))\n",
    "results.append(benchmark(NearestCentroid(), \"Nearest Centroid\"))\n",
    "results.append(benchmark(ComplementNB(alpha=0.1), \"Complement Naive Bayes\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    ('Logistic Regression', 0.973, 0.013, 0.000),\n",
    "    ('Ridge Classifier', 0.973, 0.008, 0.000),\n",
    "    ('k-Nearest Neighbors', 0.907, 0.00, 0.004),\n",
    "    ('Random Forest', 0.987, 0.314, 0.011),\n",
    "    ('Linear SVC', 0.973, 0.007, 0.000),\n",
    "    ('Log-loss SGD', 0.973, 0.009, 0.000),\n",
    "    ('Nearest Centroid', 0.973, 0.14, 0.001),\n",
    "    ('Complement Naive Bayes', 0.960, 0.003, 0.000)\n",
    "]\n",
    "\n",
    "# Mencetak hasil\n",
    "for model, accuracy, train_time, test_time in results:\n",
    "    print(f\"('{model}', {accuracy:.4f}, {train_time:.2f}, {test_time:.2f}),\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Menyiapkan data dari hasil benchmarking\n",
    "indices = np.arange(len(results))\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "clf_names, score, training_time, test_time = results\n",
    "\n",
    "training_time = np.array(training_time)\n",
    "test_time = np.array(test_time)\n",
    "\n",
    "# Plot: trade-off antara akurasi dan waktu pelatihan\n",
    "fig, ax1 = plt.subplots(figsize=(10, 8))\n",
    "ax1.scatter(score, training_time, s=80, color='skyblue')\n",
    "ax1.set(\n",
    "    title=\"Trade-off Akurasi vs Waktu Pelatihan\\n(Prediksi Status Mentee - Proyek WBL)\",\n",
    "    yscale=\"log\",\n",
    "    xlabel=\"Akurasi Pengujian\",\n",
    "    ylabel=\"Waktu Pelatihan (detik)\",\n",
    ")\n",
    "ax1.grid(True)\n",
    "\n",
    "# Menambahkan label model ke titik scatter\n",
    "for i, txt in enumerate(clf_names):\n",
    "    ax1.annotate(txt, (score[i], training_time[i]), fontsize=9)\n",
    "\n",
    "# Plot: trade-off antara akurasi dan waktu pengujian\n",
    "fig, ax2 = plt.subplots(figsize=(10, 8))\n",
    "ax2.scatter(score, test_time, s=80, color='salmon')\n",
    "ax2.set(\n",
    "    title=\"Trade-off Akurasi vs Waktu Pengujian\\n(Prediksi Status Mentee - Proyek WBL)\",\n",
    "    yscale=\"log\",\n",
    "    xlabel=\"Akurasi Pengujian\",\n",
    "    ylabel=\"Waktu Pengujian (detik)\",\n",
    ")\n",
    "ax2.grid(True)\n",
    "\n",
    "# Menambahkan label model ke titik scatter\n",
    "for i, txt in enumerate(clf_names):\n",
    "    ax2.annotate(txt, (score[i], test_time[i]), fontsize=9)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
